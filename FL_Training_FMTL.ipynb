{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29303e79-2191-48c2-88cf-d4f8f97499d9",
   "metadata": {},
   "source": [
    "# Scenario 1: All modalities exists, no heterginity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f0f1d-2404-4acf-8593-99c905a32a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transf\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_feed import DataFeed, DataFeed_image_pos\n",
    "from build_net import resnet50, NN_beam_pred, MultinomialLogisticRegression, resnet18_mod\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ca09e-bc32-4f5f-8b1e-f27a82f12f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9856d27-3d53-43f2-91fa-380f7b7fb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "val_batch_size = 1\n",
    "lr = 1e-3\n",
    "decay = 1e-4\n",
    "num_epochs = 20\n",
    "train_size = [1]\n",
    "no_users = 20\n",
    "\n",
    "val_losses_stand_alone = []\n",
    "val_losses_FL = []\n",
    "val_losses_SFMTL = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2aff42-b785-4b9f-9c54-59cef3e4af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "########################### Data pre-processing ########################\n",
    "########################################################################\n",
    "\n",
    "\n",
    "img_resize = transf.Resize((224, 224))\n",
    "img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "proc_pipe = transf.Compose(\n",
    "    [transf.ToPILImage(),\n",
    "     img_resize,\n",
    "     transf.ToTensor(),\n",
    "     img_norm]\n",
    ")\n",
    "dataset_dir = \"feature_IID/\"\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "for user_id in range(no_users):\n",
    "    train_dir = dataset_dir + f'user_{user_id}_pos_height_beam_train.csv'\n",
    "    val_dir = dataset_dir + f'user_{user_id}_pos_height_beam_val.csv'\n",
    "    test_dir = dataset_dir + f'user_{user_id}_pos_height_beam_test.csv'\n",
    "    \n",
    "    train_dataset = DataFeed_image_pos(train_dir, transform=proc_pipe)\n",
    "    val_dataset = DataFeed_image_pos(root_dir=val_dir, transform=proc_pipe)\n",
    "    test_dataset = DataFeed_image_pos(root_dir=test_dir, transform=proc_pipe)\n",
    "    \n",
    "    \n",
    "    train_loaders.append(DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              #num_workers=8,\n",
    "                              shuffle=False))\n",
    "    val_loaders.append(DataLoader(val_dataset,\n",
    "                            batch_size=val_batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "    test_loaders.append(DataLoader(test_dataset,\n",
    "                            batch_size=val_batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "    print(f\"Loaded_user: {user_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431fabe-5cae-456a-9ecb-10342010679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, (x, y) in zip(range(1), train_loaders[0]):\n",
    "    print(x[\"pos_height\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e09dd8-16e0-4181-949e-8c829098993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preperation#\n",
    "all_models = []\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "user_modalities = [available_modalities for _ in range(no_users)]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "output_sizes = [sum([modality_size[i] for i in user_modality]) for user_modality in user_modalities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e6696-0636-4b3f-bd6e-d84baacd3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store similarity matrices for each modality\n",
    "similarity_matrices = {modality: np.zeros((no_users, no_users), dtype=int) for modality in available_modalities}\n",
    "\n",
    "# Populate the similarity matrices\n",
    "for modality in available_modalities:\n",
    "    for i in range(no_users):\n",
    "        for j in range(no_users):\n",
    "            if modality in user_modalities[i] and modality in user_modalities[j]:\n",
    "                similarity_matrices[modality][i, j] = 1\n",
    "\n",
    "# Print the resulting matrices\n",
    "for modality, matrix in similarity_matrices.items():\n",
    "    print(f\"Similarity Matrix for '{modality}':\")\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a6d65-dc6d-4352-a597-d37acd1554ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(matrix, tol=1e-9, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Converts a given matrix to a doubly stochastic matrix using the Sinkhorn-Knopp algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        matrix (np.ndarray): The input matrix to be transformed.\n",
    "        tol (float): The tolerance for convergence.\n",
    "        max_iter (int): Maximum number of iterations for convergence.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A doubly stochastic matrix.\n",
    "    \"\"\"\n",
    "    matrix = matrix.copy()\n",
    "    for _ in range(max_iter):\n",
    "        # Normalize rows\n",
    "        row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "        matrix /= row_sums\n",
    "\n",
    "        # Normalize columns\n",
    "        col_sums = matrix.sum(axis=0, keepdims=True)\n",
    "        matrix /= col_sums\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(matrix.sum(axis=1), 1, atol=tol) and np.allclose(matrix.sum(axis=0), 1, atol=tol):\n",
    "            break\n",
    "\n",
    "    return matrix\n",
    "    \n",
    "def create_random_topology(num_users, edge_probability=0.3):\n",
    "    \"\"\"\n",
    "    Creates a connected random topology using NetworkX.\n",
    "    Returns the adjacency matrix.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        graph = nx.erdos_renyi_graph(num_users, edge_probability)\n",
    "        if nx.is_connected(graph):\n",
    "            break\n",
    "\n",
    "    # Convert graph to adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_array(graph)\n",
    "    return adjacency_matrix\n",
    "\n",
    "def prepare_mixing_matrices(adjacency_matrix, similarity_matrices):\n",
    "    \"\"\"\n",
    "    Computes a mixing matrix for each modality by multiplying the adjacency matrix \n",
    "    with the similarity matrix for that modality.\n",
    "    Returns a dictionary of mixing matrices.\n",
    "    \"\"\"\n",
    "    adjacency_matrices = {}\n",
    "    mixing_matrices = {}\n",
    "    for modality, similarity_matrix in similarity_matrices.items():\n",
    "        # Element-wise multiplication of adjacency and similarity matrices\n",
    "        combined_matrix = adjacency_matrix * similarity_matrix\n",
    "        adjacency_matrices[modality] = combined_matrix\n",
    "        \n",
    "        # Normalize to create a doubly matrix\n",
    "        mixing_matrix = sinkhorn_knopp(combined_matrix)\n",
    "        \n",
    "        \n",
    "        mixing_matrices[modality] = mixing_matrix\n",
    "    \n",
    "    return mixing_matrices, adjacency_matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1345c76-333e-4180-b438-4466eed22669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random connected topology\n",
    "adjacency_matrix = create_random_topology(no_users, edge_probability=0.3)\n",
    "\n",
    "# Prepare mixing matrices for each modality\n",
    "mixing_matrices, adjacency_matrices = prepare_mixing_matrices(adjacency_matrix, similarity_matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093577f9-b3f0-4713-91b9-ef34f2ab76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Decentralized aggregation function\n",
    "def decentralized_aggregation(user_models, mixing_matrices, available_modalities):\n",
    "    num_users = len(user_models)\n",
    "    \n",
    "    for modality in available_modalities:\n",
    "        # Get the mixing matrix for the current modality\n",
    "        mixing_matrix = mixing_matrices[modality]\n",
    "        \n",
    "        # Convert user model parameters to vectors for aggregation\n",
    "        aggregated_models = [torch.nn.utils.parameters_to_vector(user_model[modality].parameters()) for user_model in user_models]\n",
    "        \n",
    "        # Initialize aggregated updates\n",
    "        aggregated_updates = [torch.zeros_like(aggregated_models[0]) for _ in range(num_users)]\n",
    "        \n",
    "        # Perform model aggregation based on the mixing matrix for this modality\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_users):\n",
    "                if mixing_matrix[i, j] > 0:\n",
    "                    aggregated_updates[i] += mixing_matrix[i, j] * aggregated_models[j]\n",
    "        \n",
    "        # Update user models with aggregated parameters for the current modality\n",
    "        for i in range(num_users):\n",
    "            torch.nn.utils.vector_to_parameters(aggregated_updates[i], user_models[i][modality].parameters())\n",
    "\n",
    "\n",
    "def train_local_model(local_modalities, models, train_loader, criterion, optimizers, epochs):\n",
    "\n",
    "    for modality in local_modalities:\n",
    "        print(f\"Training for modality: {modality}\")\n",
    "        \n",
    "        model = models[modality]\n",
    "        optimizer = optimizers[modality]\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for data, labels in train_loader:\n",
    "                # Move data to GPU if available\n",
    "                data = data[modality]\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "                \n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                temp, outputs = model(data)\n",
    "                print(temp.shape)\n",
    "\n",
    "               \n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Optional: Print loss for debugging\n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}], Modality: {modality}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a079548-3c7c-46bb-bfc1-be6ad5984a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_user_models(user_id, user_models, val_loaders, criterion):\n",
    "\n",
    "    print(f\"Validating model for User {user_id + 1}\")\n",
    "\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for modality, model in user_models.items():\n",
    "            total_loss = 0.0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            model.eval()\n",
    "            if modality not in user_models.keys():\n",
    "                print(f\"Skipping modality {modality} for User {user_id + 1}, no validation data.\")\n",
    "                continue\n",
    "            \n",
    "            for data, labels in val_loaders:  # Iterate over validation data for the modality\n",
    "                data = data[modality]\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                # Forward pass\n",
    "                _, outputs = model(data)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accumulate loss and accuracy\n",
    "                total_loss += loss.item() * labels.size(0)  # Sum loss for the batch\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            # Compute metrics\n",
    "            avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "            accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        \n",
    "            print(f\"User {user_id + 1}, modality: {modality} - Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        return {'loss': avg_loss, 'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add479e-d5e9-4ca5-a38e-8ef4e3fa9a5b",
   "metadata": {},
   "source": [
    "# Sheaf_assisted FML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641d1c9-67ce-462c-bd51-65e7d4b5962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Model Preperation#\n",
    "all_models = []\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "user_modalities = [available_modalities for _ in range(no_users)]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "output_sizes = [sum([modality_size[i] for i in user_modality]) for user_modality in user_modalities]\n",
    "\n",
    "local_classifiers = [MultinomialLogisticRegression(output_sizes[i], 64).cuda() for i in range(no_users)]\n",
    "for user_id in range(no_users):\n",
    "    user_model = {}\n",
    "    if \"images\" in user_modalities[user_id]:\n",
    "        user_model[\"images\"] = resnet50(pretrained=True, progress=True, num_classes=64).cuda()\n",
    "    if \"pos_height\" in user_modalities[user_id]:\n",
    "        user_model[\"pos_height\"] = NN_beam_pred(num_features=4, num_output=64).cuda()\n",
    "    all_models.append(user_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1fd09-c62d-466a-b3c2-7bfc917594da",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 0.05\n",
    "neighbors = [np.nonzero(adjacency_matrix[i])[0].tolist() for i in range(no_users)]\n",
    "\n",
    "# Initialize P_ij matrices\n",
    "# Initialize P_ij matrices\n",
    "P = {}\n",
    "for i, j in zip(*adjacency_matrix.nonzero()):\n",
    "    num_params_i = sum(p.numel() for p in local_classifiers[i].parameters())\n",
    "    num_params_j = sum(p.numel() for p in local_classifiers[j].parameters())\n",
    "    P[(i, j)] = torch.randn(int(factor*(num_params_i + num_params_j) // 2), num_params_i).cuda()\n",
    "    P[(j, i)] = torch.randn(int(factor*(num_params_i + num_params_j) // 2), num_params_j).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2f12b-710a-4c11-8fb9-a1db91beff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_user_model_FMTL(user_id, user_models, client_model, val_loader, loss_func):\n",
    "\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        # Set all models to evaluation mode\n",
    "        client_model.eval()\n",
    "        for model in user_models.values():\n",
    "            model.eval()\n",
    "\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            # Concatenate outputs from all modality models\n",
    "            modality_outputs = []\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "            for modality, model in user_models.items():\n",
    "\n",
    "                # Forward pass through modality model\n",
    "                data = X_batch[modality].cuda()\n",
    "                modality_output, _ = model(data)\n",
    "                modality_outputs.append(modality_output)\n",
    "\n",
    "            # Skip if no valid modalities are present\n",
    "            if len(modality_outputs) == 0:\n",
    "                print(f\"No valid modalities for User {user_id + 1}, skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            # Concatenate all modality outputs\n",
    "            concatenated_output = torch.cat(modality_outputs, dim=1)\n",
    "\n",
    "            # Forward pass through the classifier\n",
    "            predictions = client_model(concatenated_output)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_func(client_model, concatenated_output, y_batch, l2_strength=0.01)\n",
    "            total_loss += loss.item() * y_batch.size(0)\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            total_correct += (predicted == y_batch).sum().item()\n",
    "            total_samples += y_batch.size(0)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    print(f\"User {user_id + 1} - Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return {'loss': avg_loss, 'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42422a44-c56d-49ae-9487-b7c0f7466c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import cross_entropy_loss_with_l2\n",
    "local_epochs = 1\n",
    "global_rounds = 50\n",
    "weight_decay = 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_func = cross_entropy_loss_with_l2\n",
    "alpha = 0.01\n",
    "lambda_reg = 0.01\n",
    "eta = 0.01\n",
    "\n",
    "# Decentralized Training\n",
    "for round_num in range(global_rounds):\n",
    "    print(f\"Global Round {round_num + 1}\")\n",
    "\n",
    "    # Training for image_modalities \n",
    "    print(\"Training image modalitity models\")\n",
    "    # Train each user's local model\n",
    "    for user_id in range(no_users):\n",
    "        print(f\"Training model for User {user_id + 1}\")\n",
    "        user_models = all_models[user_id]\n",
    "        optimizers = {}\n",
    "        for modality in user_model.keys():\n",
    "            optimizers[modality] = optim.Adam(user_models[modality].parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        train_local_model(user_modalities[user_id], user_models, train_loaders[user_id], criterion, optimizers, local_epochs)\n",
    "\n",
    "    # Decentralized aggregation\n",
    "    print(\"Performing decentralized aggregation\")\n",
    "    decentralized_aggregation(all_models, mixing_matrices, available_modalities)\n",
    "\n",
    "    # FMTL Training Part\n",
    "    print(\"Performing FMTL aggregation\")\n",
    "    for i in range(no_users):\n",
    "        client_model = local_classifiers[i]\n",
    "        user_models = all_models[user_id]\n",
    "        optimizer = optim.Adam(client_model.parameters(), lr=alpha, weight_decay=weight_decay)\n",
    "        \n",
    "        # Training the model\n",
    "        client_model.train()\n",
    "        for X_batch, y_batch in train_loaders[i]:\n",
    "            # Ensure all modality models are in evaluation mode\n",
    "            for modality, model in user_models.items():\n",
    "                model.eval()\n",
    "        \n",
    "            # Concatenate outputs from all modality models\n",
    "            modality_outputs = []\n",
    "            for modality, model in user_models.items():\n",
    "                with torch.no_grad():  # Do not compute gradients for modality models \n",
    "                    data, y_batch = X_batch[modality].cuda(), y_batch.cuda()\n",
    "                    modality_output, _ = model(data)\n",
    "                    modality_outputs.append(modality_output)\n",
    "\n",
    "        \n",
    "            # Concatenate all modality outputs\n",
    "            concatenated_output = torch.cat(modality_outputs, dim=1)\n",
    "\n",
    "            # Forward pass through the classifier\n",
    "            optimizer.zero_grad()\n",
    "            predictions = client_model(concatenated_output)\n",
    "            \n",
    "                    \n",
    "            # Compute the loss\n",
    "            loss = loss_func(client_model, concatenated_output, y_batch, l2_strength=0.01)\n",
    "        \n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            theta_i = torch.cat([param.view(-1) for param in client_model.parameters()])\n",
    "    \n",
    "            # Update theta_i based on P_ij and neighbors\n",
    "            sum_P_terms = torch.zeros_like(theta_i)\n",
    "            for j in range(no_users):\n",
    "                if adjacency_matrix[i, j] == 1:\n",
    "                    P_ij = P[(i, j)]\n",
    "                    P_ji = P[(j, i)]\n",
    "                    theta_j = torch.cat([param.view(-1) for param in local_classifiers[j].parameters()])\n",
    "                    sum_P_terms += P_ij.T @ (P_ij @ theta_i - P_ji @ theta_j)\n",
    "    \n",
    "            # Apply update to theta_i\n",
    "            theta_i -= alpha * lambda_reg * sum_P_terms\n",
    "    \n",
    "            # Put updated theta_i back into the model\n",
    "            idx = 0\n",
    "            for param in client_model.parameters():\n",
    "                numel = param.numel()\n",
    "                param.data.copy_(theta_i[idx:idx+numel].reshape(param.size()))\n",
    "                idx += numel\n",
    "    \n",
    "            # Update P_ij matrices\n",
    "            for j in range(no_users):\n",
    "                if adjacency_matrix[i, j] == 1:\n",
    "                    P_ij = P[(i, j)]\n",
    "                    P_ji = P[(j, i)]\n",
    "                    theta_j = torch.cat([param.view(-1) for param in local_classifiers[j].parameters()])\n",
    "    \n",
    "                    # Update P_ij\n",
    "                    P[(i, j)] -= eta * lambda_reg * torch.outer(P_ij @ theta_i - P_ji @ theta_j, theta_i)\n",
    "        \n",
    "\n",
    "    # Optionally, validate models\n",
    "    print(\"Validating user models...\")\n",
    "    for user_id in range(no_users):\n",
    "        user_models = all_models[user_id]\n",
    "        client_model = local_classifiers[i]\n",
    "        val_dict = validate_user_model_FMTL(user_id, user_models, client_model, val_loaders[user_id], loss_func)\n",
    "        val_losses_SFMTL.append(val_dict)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Decentralized federated learning complete.\")\n",
    "\n",
    "file_path = 'val_losses_SFMTL.json'\n",
    "\n",
    "# Save the list of dictionaries to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(val_losses_SFMTL, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c2fc9-8e70-4b8a-b028-5a12a82cb7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
